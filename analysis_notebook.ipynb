{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20373167",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da92bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fairness\n",
    "from fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference, selection_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc00c6f",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "\n",
    "The **UCI Adult Income dataset** is used to predict whether a person earns more than \\$50K/year.  \n",
    "\n",
    "\n",
    "The raw dataset requires preprocessing because:  \n",
    "- It **has no headers**, so column names must be assigned.  \n",
    "- It contains **categorical variables** (e.g. `workclass`, `education`, `occupation`) and the model expects numerical input.  \n",
    "- It uses `?` for **missing values** that the model cannot handle directly.  \n",
    "\n",
    "\n",
    "Preprocessing steps:  \n",
    "1. Assign column names.  \n",
    "2. Drop rows with missing values.  \n",
    "3. Convert the target variable `income` to **binary classification** (0 = â‰¤50K, 1 = >50K).  \n",
    "4. One-hot encode categorical features.  \n",
    "\n",
    "\n",
    "The dataset is then ready for modelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba675d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# Define column names as UCI dataset has no headers\n",
    "column_names = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\n",
    "    'adult.data', \n",
    "    header=None, \n",
    "    names=column_names, \n",
    "    na_values='?', \n",
    "    sep=r',\\s*', \n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert target variable to binary format\n",
    "data['income'] = (data['income'] == '>50K').astype(int)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = [\n",
    "    'workclass', 'education', 'marital-status',\n",
    "    'occupation', 'relationship', 'race',\n",
    "     'sex', 'native-country'\n",
    "]\n",
    "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop(['income', 'fnlwgt'], axis=1)\n",
    "y = data['income']\n",
    "\n",
    "print(\"Data preparation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd080644",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "\n",
    "A **Logistic Regression classifier** is used as a starting point as it is simple, fast and works well for binary classification.\n",
    "\n",
    "\n",
    "The dataset is split into **80% training data** and **20% testing data**.\n",
    "\n",
    "\n",
    "**Feature scaling** is applied to help the model learn more efficiently (faster convergence) and produce more consistent results.\n",
    "\n",
    "\n",
    "The model is trained on the scaled training data, and predictions (`y_pred`) are made on the test set.\n",
    "\n",
    "\n",
    "The model's performance is measured using **accuracy**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23033095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialise Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000, solver='lbfgs')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1ec26",
   "metadata": {},
   "source": [
    "The Logistic Regression model achieves around **85% accuracy** on the test set.\n",
    "This serves as a baseline for testing other models and potential improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ac969",
   "metadata": {},
   "source": [
    "## Fairness Audit\n",
    "\n",
    "The model is audited for bias using the **Fairlearn** library, focusing first on the sensitive feature of sex to see if its predictions are fair.\n",
    "- **MetricFrame** is used to group **accuracy** and **selection_rate** (how often >$50K predicted) into males and females to measure the model's performance and outcome gaps.\n",
    "\n",
    "- **Demographic Parity** is calculated to show the bias in positive outcomes between groups.\n",
    "\n",
    "- **Equalised Odds** is calculated to see if the model is making errors at a similar rate across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e7985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fairness Audit: Sex ----\n",
      "\n",
      "Performance and Selection Rates by Group:\n",
      "           accuracy  selection_rate\n",
      "sex_Male                          \n",
      "False     0.928608        0.080571\n",
      "True      0.815570        0.265963\n",
      "\n",
      "Demographic Parity Difference (bias in outcomes): 0.185\n",
      "Equalised Odds Difference (bias in error rates): 0.086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract sensitive feature for fairness analysis\n",
    "sensitive_sex = data.loc[X_test.index, 'sex_Male']\n",
    "\n",
    "# Compute metrics by group\n",
    "metrics_by_sex = MetricFrame(metrics={'accuracy': accuracy_score, 'selection_rate': selection_rate},\n",
    "                             y_true=y_test,\n",
    "                             y_pred=y_pred,\n",
    "                             sensitive_features=sensitive_sex)\n",
    "\n",
    "# Compute main fairness difference metrics\n",
    "dpd_sex = demographic_parity_difference(y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_sex)\n",
    "eod_sex = equalized_odds_difference(y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_sex)\n",
    "\n",
    "# Print a clear report\n",
    "print(\"--- Fairness Audit: Sex ----\\n\")\n",
    "print(\"Performance and Selection Rates by Group:\\n\", metrics_by_sex.by_group)\n",
    "print(f\"\\nDemographic Parity Difference (bias in outcomes): {dpd_sex:.3f}\")\n",
    "print(f\"Equalised Odds Difference (bias in error rates): {eod_sex:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe746f54",
   "metadata": {},
   "source": [
    "## Fairness Audit Results (Sex)\n",
    "\n",
    "The results show a clear bias in how the model performs and its outcomes based on sex.\n",
    "\n",
    "- **Accurcy:** The model is far better at predicting income for females (92.9%) than for males (81.6%).\n",
    "\n",
    "- **Outcomes:** The Demographic Parity Difference is **high** (0.185), which confirms the model is biased as it predicts a high income (>$50K) for men much more often than for women.\n",
    "\n",
    "**Conclusion:** With respect to sex, the model is not fair, as it appears to be replicating historical biases found in the 1994 data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
